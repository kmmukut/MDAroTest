{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv(\"digits.csv\", header=None) #read the given csv\n",
    "dataSet = dataSet.sample(frac=1).reset_index(drop=True) #randomize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataSet[dataSet.columns[:-1]] #delete the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=dataSet.iloc[:,-1].values #separate the class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "className=[i for i in range(10)] #define class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classMean= pd.DataFrame(columns=className) #creating new dataFrame for class mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classColumn=dataSet.columns[data.shape[1]] #index of columns in which the classes are specified\n",
    "for i, rows in dataSet.groupby(classColumn): #group by the class column and take mean\n",
    "    classMean[i]=rows.mean()\n",
    "classMean.drop(classMean.tail(1).index, inplace=True) #delete the mean of the class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "withinClassCovariance=np.zeros((data.shape[1],data.shape[1])) #Creating Sw\n",
    "for i, rows in dataSet.groupby(classColumn):\n",
    "    rows=rows.drop([classColumn], axis=1)\n",
    "    Sk=np.zeros((data.shape[1],data.shape[1]))\n",
    "    for j, row in rows.iterrows():\n",
    "        x, mi = row.values.reshape(data.shape[1],1), classMean[i].values.reshape(data.shape[1],1)\n",
    "        Sk += (x - mi).dot((x - mi).T)\n",
    "    withinClassCovariance += Sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenClassCovariance=np.zeros((data.shape[1],data.shape[1])) #Creating SB\n",
    "for i in classMean:\n",
    "    n=len(dataSet.loc[dataSet[classColumn]==i].index)\n",
    "    mc =  classMean[i].values.reshape(data.shape[1],1)\n",
    "    m = data.mean().values.reshape(data.shape[1],1)\n",
    "    betweenClassCovariance += n*(mc-m).dot((mc-m).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcJ = np.dot(np.linalg.pinv(withinClassCovariance), betweenClassCovariance)\n",
    "eigvals, eigvecs = np.linalg.eig(calcJ)\n",
    "eiglist = [(eigvals[i], eigvecs[:, i]) for i in range(len(eigvals))]\n",
    "eiglist = sorted(eiglist, key = lambda x : x[0], reverse = True)\n",
    "eiglist\n",
    "eigen_value_sums = sum(eigvals)\n",
    "W=np.array([eiglist[i][1] for i in range (2)]).real #generate W matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = np.array(data.dot(W.T)) #LDA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mean, std):  #creating the Gaussian Model\n",
    "    calc = 1. / ((2 * np.pi) ** (len(x) / 2.) * np.linalg.det(std) ** (-0.5))\n",
    "    return calc * np.exp(-np.dot(np.dot((x - mean), np.linalg.inv(std)), (x - mean).T) / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Likelihood(train,classes,projection, PiK, sigma, mu):  #likelihood function\n",
    "    MLR = []\n",
    "    for i in projection:\n",
    "        MLRvalue = []\n",
    "        for j in classes: \n",
    "            pdfValue = gaussian(i, mu[j], sigma[j])\n",
    "            MLRvalue.append(PiK[j]*pdfValue)\n",
    "\n",
    "        MLR.append(MLRvalue)\n",
    "    return np.asarray(MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(dataset): #function for error calculation\n",
    "    data = dataset.drop([classColumn],axis=1)\n",
    "    dataGroup = dataset.groupby(dataSet.iloc[:,-1])\n",
    "    classes = dataGroup.groups.keys()\n",
    "    \n",
    "    trainData = {i:dataGroup.get_group(i) for i in classes}\n",
    "    PiK = {}\n",
    "    mu = {}\n",
    "    sigma = {}\n",
    "    for j in classes:\n",
    "        classData = trainData[j].drop([classColumn], axis=1)\n",
    "        projection = np.dot(W, classData.T).T\n",
    "        PiK[j] = classData.shape[0]/dataSet.shape[0]\n",
    "        mu[j] = np.mean(projection,axis=0)\n",
    "        sigma[j] = np.cov(projection, rowvar = False)\n",
    "    projection = np.dot(W, data.T).T\n",
    "    likelihood = Likelihood(data,classes, projection,PiK,sigma,mu )\n",
    "    labels = np.argmax(likelihood, axis=1)\n",
    "    errors = np.sum(labels != dataset.iloc[:, classColumn])\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "ratio = 1/fold\n",
    "index_at = 0\n",
    "testSize = math.ceil(data.shape[0] * 0.1)\n",
    "errorList = []\n",
    "\n",
    "for k in range(fold):\n",
    "    trainTestData = dataSet\n",
    "\n",
    "    trainData = {}\n",
    "    testData  = {}\n",
    "\n",
    "    testData = trainTestData.iloc[index_at: index_at + testSize]\n",
    "    trainData = trainTestData.drop(dataSet.index[index_at: index_at + testSize])\n",
    "    \n",
    "    testErrors = error(testData)\n",
    "    trainErrors = error(trainData)\n",
    "    \n",
    "    KFoldError = [trainErrors/len(trainData)*100.0, testErrors/len(testData)*100.0 ]\n",
    "    errorList.append(KFoldError)\n",
    "\n",
    "    index_at = index_at + testSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorHistory = pd.DataFrame(errorList, columns = [\"Train Error(%)\", \"Test Error(%)\"], index=list(range(1,11)))\n",
    "errorMean=errorHistory.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Train Error(%)  Test Error(%)\n",
      "1        31.663575      30.555556\n",
      "2        31.045145      33.888889\n",
      "3        33.580705      26.111111\n",
      "4        31.416203      41.111111\n",
      "5        31.849103      42.222222\n",
      "6        32.220161      26.666667\n",
      "7        32.714904      32.777778\n",
      "8        32.405690      33.333333\n",
      "9        33.395176      31.666667\n",
      "10       33.641975      35.028249\n",
      "Train Error(%)    32.393264\n",
      "Test Error(%)     33.336158\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(errorHistory)\n",
    "print(errorMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
